# Statistical Modeling: The Two Culture
## Summary of the paper
The paper introduced two main ideas of using statistical modeling to conclude from data. The first was based on the assumption that data was generated by given stochastic models. the second used algorithmic models with unknown data structure. By the authors' saying, the two appaoraches were used to reach the goals of prediction and extracting information. He claimed that the focus in the statistical community on data models led to irrevalent theory and unscientific conclusions, preventing them using better algorithmic models and innnovation. Genearlly, the authors provided the reasons why he raised these concerns and made the claims. The authors then argued using a couple examples, stating that his personal feeling about the lack of model fit checking, which could lead to wrong conlcuison and wrong representation of nature.
The limitation of data models and emergence of new tools like neural networks transited the authors' mind, leading to his analysis on three lessons from the machine learning rapid development. He also emphasized that the primary goal of predictive models should be to provide accurate information about the relationships between variables, even though the models are complex and less interpretable. In the end, he discussed the flexibility to choose different modeling approaches and encouraged statisticians to return to the core principles of working with data.

## Reaction to the paper
First of all, the author seems to be a pragmatist who would like to see every theory gets developed can be useful in application. I agreed that some of the theories may not even work in real life in the end, but it is hard to deny all theoretical work without an immediate application. They can in fact contribute to future theory work, which may be beneficial. He mentioned the emegerence of new community using neural nets and decision trees, prasing the way to validate model performances via prediction accuracy. However, we now all know simple accuracy cannot be used as the only criterion to asssess peformances. The more important thing is to be careful of what assaumptions to be used (maybe we could try to avoid redundant unnecessary assumptions), and interpretation of the models that we have used. In contrary, I kind of like the statement when the author said the goal of modeling is for getting information no matter how, though I think science discovery should be based on the original hypothesis instead of just data.

## Questions for discussion
What are the challenges we are faced with the increasing amount of data in fields like genetics using traditional statistics and the application of data models?

What do you believe is the future of statistics in an era of big data in various fields?

